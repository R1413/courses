Final Exam Information 
=

**Time**/**Date**: 8. May from 7:30-10:00pm in **ECCE 1B41**  

Overview and Rules  
--------
- The final exam is cumulative but will emphasize material covered after the midterm (starting with Decision Trees). This includes all material presented in videos, in-class discussion, in-class exercises, and material introduced in homework
- You are allowed **TWO** 8-1/2 x 11in sheet of **handwritten** notes (both sides).  No magnifying glasses! 
- A calculator is strongly recommended.   Any calculator that cannot access the internet or store large amounts of data may be used. Smartphones may **NOT** be used as calculators.
- The exam will be a mixture of multiple choice questions and free-response questions in which you may be asked to work through simple examples of algorithms or proofs.  Like the midterm, you will be given multiple free-response questions from which to choose a subset to work.  
- **IMPORTANT**: We will be using Scantron forms for the multiple choice questions.  Please bring a Number 2 pencil to the exam. 


Material Overview 
---

**General**
- differences between classification and regression 
- differences between supervised and unsupervised learning 
- basic probability 

**K-Nearest Neighbors**
- how the algorithm works 
- how to perform classification with the algorithm 
- properties of the algorithm 
- don't need to know about data structure

**Naive Bayes**
- assumptions behind the algorithm 
- how to compute probabilities from training data 
- how to perform classification with the algorithm 
- Laplace smoothing and it's variants 

**Logistic Regression**
- assumptions behind the algorithm 
- its probabilistic interpretation 
- how to perform classification with the algorithm 
- how to find the weights using Stochastic Gradient Ascent 
- how to efficiently perform regularization in the context of SGA 

**Multi-class Classification**
- One-vs-All classification 
- All-Pairs classification 
- Error Correcting Output Codes 

**Model Validation and Evaluation Metrics**
- K-Folds cross-validation 
- Confusion matrices
- TPR vs FPR 
- ROC curves 
- Residual plots 

**Feature Engineering** 
- Text models (BOW and tfidf)
- Residual plots 

**Regression**
- probabilistic interpretation of regression models 
- generalities of how weights are estimated 
- interpretation of the weights in regression models 

**Regularization** 
- the point of regularization 
- Ridge (L2) Regression 
- LASSO (L1) Regression 
- Ridge vs LASSO regression 
- the effect on bias/variance 
- **WON'T** ask you about material on solving for regularized regression weights (Lecture 9 in-class notebook)

**Learning Theory**
- the Bias/Variance Trade-Off
- overfitting, generalization, etc 
- finite vs infinite hypothesis classes 
- PAC Learnability: what it means, what is involved, simple bounds (but no proofs) 
- VC Dimension: how to compute it (possibly simple proofs), why it matters 

**Support Vector Machines** 
- the concept of a margin 
- the geometry behind SVM 
- the workings of hard-margin SVM 
- the workings of soft-margin SVM 
- what a support vector is 
- ideas related to different kernels 

**Decision Trees** 
- general properties of the algorithm 
- entropy, impurity, and information gain 
- how to choose the best split 

**Boosting**
- properties of the AdaBoost algorithm 
- the concept of a weak learner 
- how weights are calculated in AdaBoost 
- how predictions are made from an AdaBoost model 

**Neural Networks**
- Single and Multilayer Perceptrons
- Feed-Forward Neural Networks 
- Forward and Backpropagation 
- SGD for learning weights 

**Principal Component Analysis**
- How it works 
- Use in dimensionality reduction 
- Explained Variance 
- **WON'T** ask you to actually perform PCA 

**K-Means and Gaussian Mixture Models** 
- Properties of the K-Means algorithm 
- how clusters are found in K-Means 
- properties of GMMs
- the Expectation-Maximization algorithm 
- comparison of K-Means and GMMs

**Hidden Markov Models** 
- General form of an HMM 
- Filtering, Smoothing, and Most Likely Sequence of States
- Forward, Forward-Backward, and Viterbi's Algorithms 
- **WON'T** ask you to explicitly perform Forward-Backward or Viterbi, since we didn't do explicit examples in class

**Reinforcement Learning** 
- general concepts (states, actions, transitions, rewards, policies, etc.)
- Value Iteration with cumulative value function 
- Grid-World examples 
- Q-Learning and Temporal Difference Learning 
- **WON'T** ask you to explicitly perform TD for Q-Learning, since we didn't do explicit examples in class 
- **WON'T** ask about using neural networks in Q-Learning 














